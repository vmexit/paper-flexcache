\section{Motivation}
\label{s:motivation}
Prior work designs the cache replacement policy for a specific access pattern and cache size, but its performance decreases when the access pattern changes or even the cache size varies (\S\ref{ss:performance-policy-change}).
%
We propose a method to split the trace based on the cache size into phases and mark objects into different types according to their popularity in different phases (\S\ref{ss:split-trace}).
%
Based on the phase aware and cache size aware method, we will discuss why we should take the overall cache access behavior into account and design an adaptive cache replacement policy (\S\ref{ss:dynamic-adjust}).
%\sys decides whether to retain an object based on its type and phases information to fit in various cache sizes and access patterns.
%

This section presents why we need a phase aware and cache size aware method to implement a replacement policy (\S\ref{ss:performance-policy-change}), how we implement it (\S\ref{ss:split-trace}), and what to do for adaption (\S\ref{ss:dynamic-adjust}).

\subsection{Performance degradation with different cache size}
\label{ss:performance-policy-change}
Many policies suffer performance degradation when the cache size and access pattern change. 
%
We evaluate \XXX{XX} policies in \XXX{XX} traces with different cache sizes and calculate the relative hit ratio to the the best policy in the policy set.
%
All policies achieve the best performance in a specific cache size and suffer from a tail performance about 20\% to 60\% relative hit ratio to the best policy.
%
Therefore, if we use a specific replacement policy for all traces in the benchmkars, there are \XXX{XX}\% of traces that will lose \XXX{XX}\% performance.
%
What's more even, with the same trace, if we slightly change the cache size without adjusting the replacement policy, more than 5\% of the performance potential may remain unexploited.
%
It is a disaster in the production environments.
%It is common that a designed replacement policy perform well in a specific access pattern, so we should choose a policy for a trace in the production environments.
%

As shown in figure ~\autoref{fig:cloudphysics}, we evaluate the performance of \XXX{XX} cache replacement policies~\cite{} in Cloudphysics~\cite{}. 
%
CloudPhysics provides \XXX{XX} traces. 
%
We evaluate the hit ratio of \XXX{XX} replacement policies under a given cache size. 
%
For each trace, we select the replacement policy with the highest hit ratio as the optimal policy. 
%
Then, we calculate the performance of each policy relative to the optimal policy and compute the geometric mean across all traces.
%
We observe that S3FIFO performs better when the cache size is small, while LIRS performs better when the cache size is large. 
%
Most replacement policies achieve an average performance of under 95\%, which means that using the same replacement policy for all traces would result in sacrificing nearly 5\% of potential performance gains.
%
While \sys is the best policy in all cache sizes, it is the best policy in \XXX{XX}\% percent of traces.


As shown in figure ~\autoref{fig:cache-size}, ARC~\cite{} and LIRS~\cite{} achieve the best performance in different cache sizes in systor~\cite{}. 
%
We select the replacement policy with the highest hit ratio as the optimal policy and compute the relative hit ratio of each policy to the optimal policy.
%
In figure ~\autoref{fig:cache-size}, when the cache size enlarges from 5GB to 6GB(\TODO{true cache size}), LIRS is the best policy, and others performance degrade about 5\%.
%
When the cache size is larger than 7 GB to 20BG, QDLP is the best policy.
%
When we take \sys into consideration, it is the best policy and outperforms other policies about 2\%.


%
\begin{figure}[t]
    \centering
    \includegraphics[width=\columnwidth]{fig/demo-cloudphysics}
    \caption{Cache replacement policies' performance with different cache sizes in Cloudphysics.(\TODO{maybe a specific trace or violin plot})}
    \label{fig:cloudphysics}
\end{figure}


\begin{figure}[t]
    \centering
    \includegraphics[width=\columnwidth]{fig/demo-cachesize.pdf}
    \caption{Cache replacement policies' performance with different cache sizes.}
    \label{fig:cache-size}
\end{figure}


\subsection{Phase aware to cache size aware}
\label{ss:split-trace}
To design a cache size aware replacement policy, we analyze the relationship between the cache size and the trace by splitting the trace into phases based on the cache size.
%
Prior work~\cite{} analyzes the trace based on a period of time or a fix numbers of accesses, and when the miss ratio changes, they think there is a phase change.
%
This method reveals that requests for objects change with time, but it is not accurate to adjust the cache replacement policy.
%
We propose that if a set of requests' footprint is less than the cache size, they are in the same phase.
%

We use this cache size aware method to analyze the trace in Alibaba~\cite{} and find a different way to mark the object types. 
%
As shown in figure~\ref{fig:wss}, we set the cache size as 0.02 and 0.03 working set size, split the trace into phases, with each phase's footprint equal to the cache size, and count the frequency of each object in the phase. (\TODO{find a real world trace})
%
\begin{figure}[t]
    \centering
    \includegraphics[width=\columnwidth]{fig/demo-wss002.png}
    \caption{In different cache sizes, the object types change in Alibaba.}
    \label{fig:wss}
\end{figure}


%According to how many times the object accessed and how many phases it appears, we mark the object into four types dynamicly.  \dots
We categorize objects into four types based on the number of accesses and phases in which they appear. 
%
They are classified as frequently accessed (FA) and infrequently accessed (IA) objects based on their access frequency and divided into multi-phase (MP) and few-phase (FP) objects based on their occurrence across phases.
%
\sys dynamically marks the objects into four types: FA-MP, FA-FP, IA-MP, and IA-FP.
%
It hold FA-MP objects, treats FA-FP and IA-MP as suspected objects, and filters IA-FP objects.


Prior work cannot dynamically mark the object types, because they are too positive to the objects in the filter cache and ghost cache.
%
They designs replacement policies~\cite{} to retain FA-MP objects while quickly evicting IA-FP objects.
%
For instance, LFU is good at retaining FA objects, while LRU prefers MP objects.
%
However, they do not analyze the object from the whole trace, but only from the ghost and filter cache, which is not enough to determine the object type.
%
Cacheus and LeCaR adjust the policy based on the access in the ghost cache, and their miss ratio waves greatly when the cache size changes in figure \TODO{}.
%
ARC thinks a request hitting in the filter cache or the ghost cache is important, so it moves the object to the main cache.
%
This behavior do not discover the overall access behavior, which hurts the performance even if enlarges the cache size in figure \TODO{}.
%However, they use static criteria to categorize objects and fail to analyze the type distribution to fit the cache size, leading to huge performance variations with different cache sizes.(\TODO{ figure maybe figure cacheus in fiu, mrc waves})


Figure ~\ref{fig:exapmle} shows the object types changes in different cache sizes. 
%
For the access \cc{ABCDABEFABACGAH}, if we use footprint four to split the trace, only \cc{A} is FA-MP object. 
%
\cc{B} and \cc{C} are FA-FP and IA-MP objects, and others are IA-FP objects. 
%
While if we use footprint six to split the trace, \cc{A}, \cc{B}, and \cc{C} are FA-MP objects. 
%
With this method, the access pahses change with the cache size, and the object types change with the access phases and cache size.
%
We use a sliding window and an appropriate aging function to dynamicly discover what objects are in the same phase.
%
In figure ~\ref{fig:exapmle}, when the footptint is four, there is a request for \cc{E}, we age \cc{A}, \cc{B}, and \cc{C}, and finally we decide to evict \cc{C} in the sliding window.
%
While if the footprint is six and there is a request for \cc{G}, we keep \cc{A}, \cc{B}, and \cc{C} after aging, and evict \cc{D} to keep the phase.
%
\sys intergrates the sliding window and aging function to the replacement policy only with a few bits as S3-FIFO.


\begin{figure}[t]
    \centering
    \includegraphics[width=\columnwidth]{fig/demo-exapmle.png}
    \caption{An exapmle for the object types changes in different cache sizes.}
    \label{fig:exapmle}
\end{figure}

\subsection{Dynamicly fit the phase and cache size}
\label{ss:dynamic-adjust}
When the cache size changes, objects are marked as different types, so we must dynamically change the criteria to collect important objects.
%
We analyze all traces and find that only small parts of objects are frequently accessed.
%
In the large cache sizes, most objects are accessed many times, so we need to improve the criteria; otherwise, in the small cache sizes, most objects are accessed a few times, so we need to relax the criteria or even hold suspected objects.

We analyze the trace by counting the times an object is accessed and calculating the average resue time, discovering a linear-logarithmic relationship between them.
%
A small amount of objects are accessed many times, while a large amount are accessed only a few times. 
%
The object accessed frequently has a very short average reuse time, meaning that an object accessed multiple times within a phase is more likely to be important.
%
As figure~\ref{} \dots

If the cache size is relatively large, there are too many objects accessed many times, so we need to improve the criteria to filter out the important objects. \dots (fiu analyze)
%

If the cache size is relatively small, some data may not be accessed until several phases later. We need to speculatively retain these data. \dots (small cache analyze)


