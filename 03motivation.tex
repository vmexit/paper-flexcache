\section{Phase and hotness aware classification}
\label{s:phase-hotness}
It is a challenge to identify different access patterns in the workload.
%
Prior work classifies primitive access patterns based on access frequency and recency as we discussed in \S\ref{ss:access-pattern-based-analysis}.
%
Unfortunately, this type of classification leaves a huge portion of undefined accesses between the discrete access patterns, and the non-adaptive analysis has limited capability to guide the design of online algorithms.
%
To overcome this challenge, this paper proposes a new perspective to \textbf{adaptively} classify the workload into \textbf{cooperative} types based on \textit{phase and hotness} and converts it into an \textbf{online} version to guide the design of a reliable cache eviction algorithm in different cache sizes~(\TODO{ref design}).

This section presents how phase size reveals the intrinsic locality property of workloads~(\autoref{ss:adaptive-phases}), how different hotness during phases reflects locality changes~(\autoref{ss:hotness-during-phases}), and the characteristics of the four primitive types based on phase and hotness~(\autoref{ss:phase-hotness-based-types}).
\XXX{llj: maybe, online phase version is designed for online property, hotness is designed for cooperative property, and \sys classifies the types adaptively based on both phase and hotness.}

\subsection{Locality in phases}
\label{ss:adaptive-phases}
Phase analysis is significant to understand the locality of workloads.
%
Prior work analyzes phases based on a fixed interval to capture the periodicity of accesses~\cite{}.
%
Predefined intervals are helpful to find the \textit{daily or long-term periodicity} of accesses, indicating user behaviors, and adjust the cache behavior periodicity.
%
However, this kind of metric does not a guidance for access patterns and design of cache eviction algorithms.
%
This paper analyzes the phase adaptively and reveals the intrinsic locality property of workloads.

Rather than splitting the trace based on a \textit{fixed time interval} or a \textit{fixed number} of accesses, we split the trace based on a relative size of working set size (WSS).
%
More specifically, the number of accesses in a phase is changed adaptively, but the unique data in a phase is limited to a predefined size called footprint size.
%
We analyze the workload with different footprint sizes, a relative size of WSS, and the length of a phase indicates the locality of filling an empty cache.
%
With a fixed footprint size for a workload, the less number of phases and the longer the phase, the better locality it has.

We classify the data into \textbf{persistent} and \textbf{ephemeral} types dynamically based on the number of phases in which the data appears, which reveals the intrinsic locality property of workloads.
%
Phase size also affects the data that appears in different phases.
%
With a large phase size equal to WSS, there is only one phase, and all data appears in this phase as persistent types, which means that if the cache size is large enough, all data can be cached with good locality.
%
With a small phase size as footprint one, almost all accesses are in different phases, and there is no locality for extremely small cache size to store ephemeral types.
%
In the other cases, the data is distributed in different phases, and persistent types appear more often than ephemeral types.

\begin{figure}[t]
    \centering
    \includegraphics[width=\columnwidth]{fig/cachesizeaware.drawio.pdf}
    \caption{Phase-based classification.(1) Split the workload into phases based on the footprint size. 
    (2) The sliding window and aging function dynamically mark the object types.
    With a large phase size as footprint six, \cc{A}, \cc{B}, and \cc{C} appears for all phases.
    With a small phase size as footprint four, only \cc{A} appears in all phases, and \cc{B} and \cc{C} occur in some phases.
    }
    \label{fig:Phase-based}
\end{figure}

As shown in figure~\ref{fig:Phase-based}(1), we demonstrate how to split the trace into phases based on the footprint size and type the accesses dynamically in contiguous phase type space.
%
For the access \cc{ABCDABEFABACGAH}, if we use footprint four to split the trace, there are three phases: \cc{ABCDAB}, \cc{EFABA}, and \cc{CGAH}.
%
\cc{A} appears in all phases as a persistent type, and \cc{D}, \cc{E}, \cc{F}, \cc{G}, and \cc{H} appear in only one phase as ephemeral types.
%
Compared to ephemeral types, \cc{B} and \cc{C} appear in two phases and are more likely to be persistent type in a contiguous phase type space.
%
While if we use footprint six to split the trace, there are two phases: \cc{ABCDABEF} and \cc{ABACGAH}.
%
\cc{A}, \cc{B}, and \cc{C} appear in all phases as persistent types, and \cc{D}, \cc{E}, \cc{F}, \cc{G}, and \cc{H} appear in only one phase as ephemeral types.

Splitting a workload into phases does not match the online algorithm's workflow, and we propose an optimized \textbf{online version} for \sys~(\TODO{ref}).
%
A sliding window with a fixed footprint size provides the same effect to splitting the trace into phases in a fine-grained manner.
%
To reduce the space overhead of recording all accesses in the sliding window, a FIFO queue with a frequency counter has a similar effect to the sliding window, which also hold the relative access sequence.
%
An object enters the head of FIFO queue when its phase begins and is aged at the tail of the queue, indicating the end of the phase.
%
As shown in figure~\ref{fig:Phase-based}(2), with footprint four, \cc{ABCDAB} fill the FIFO queue, and the aging function is halfing the frequency counter and evicting the object with a zero counter.
%
In this case, \cc{A} and \cc{B} are persistent types, others are ephemeral types, and \sys will catch \cc{C} with a Sketch~\cite{}.
%
While with footprint six, \cc{ABC} are persistent types, and others are ephemeral types.

\subsection{Hotness during phases}
\label{ss:hotness-during-phases}
Phase analysis splits the workload adaptively, and hotness analysis reveals the locality changes during phases.
%
The hotness of data indicates how frequently it is accessed in a phase, and the more times it is accessed, the hotter it is with better locality for caching.
%
When we conpare the hotness of data in different phases, changed hotness indicates the transformation of locality.
%
The hotness analysis is a compensation for phase analysis.

We classify the data into \textbf{frequent} and \textbf{infrequent} types dynamically based on access hotness in a phase.
%
To properly classify the data, we collect the access frequency distribution of data in the phase as hotness information.
%
Without lose of generality, only a part of data can be kept in the cache, so we can choose a portion of data to be cached based on access frequency.
%
Then, we sort data accesses by frequency in descending order, and progressively fill the portion.
%
The access frequency at which reaches the portion is treated as the threshold to separate frequent and infrequent types.
%
The threshold changes with the target portion adaptively in different phases.

As shown in figure~\ref{fig:wss}, hotness changes with phase and phase size.
%
In the figure, a workload slice from Alibaba~\cite{} is split into phases with different phase sizes, and the access frequency distribution is shown in heatmap.
%
\XXX{For visualization, we cap the maximum frequency at 4; values above 4 are still represented as 4, and we cut off some data accessed only once in this slice.}
%
Frequent data (accessed more than four times in a phase) are more likely to be accessed in the following phases, indicating good locality for caching.
%
For example, in figure~\ref{fig:wss}(a), half of the objects accessed in phase 0 are active in the rest phase.
%
If not, phase access preference changes, and for example, frequent data in phase 3, 7 and 11 have a huge gap.
%
When the phase size is larger, frequent data are concentrated exhibiting better locality, as shown in figure~\ref{fig:wss}(b).

Hotness analysis is also an offline version, and it can cope with the online phase analysis~(\ref{ss:adaptive-phases}) to form an online version for \sys~(\TODO{ref}).
%
The offline hotness analysis collects the access frequency distribution and classifies data based on the threshold at the end of each phase.
%
In the online version, access frequency distribution manages data in the FIFO queue for a phase.
%
When access or aging occurs, it uses the new distribution to update the threshold dynamically.
%
With the new threshold, the online analysis classifies data into frequent and infrequent types.
%
It can also classify data when threshold changes due to access or aging occurs to reduce the overhead.


\subsection{Phase and hotness based types}
\label{ss:phase-hotness-based-types}
New types

hold the recency and frequency properties.

New properties

\begin{figure}[t]
    \centering
    \includegraphics[width=\columnwidth]{fig/phase.png}
    \caption{Access phases in Alibaba for different cache sizes.\TODO{update}}
    \label{fig:wss}
\end{figure}

For the basic cache size aware, we split the trace into phases when the footprint is the same as the cache size.
%
We use this cache size-aware method to analyze the trace in Alibaba~\cite{} and find a different way to mark the object types. 
%
As shown in figure~\ref{fig:wss}, we set the cache size as 10\% and 15\% WSS, split the trace into phases, with each phase's footprint equal to the cache size, and count the frequency of each object in the phase.
%
For the same workload slice, there are 12 phases with 10\% WSS and 8 phases with 15\% WSS.
%
In figure~\ref{fig:wss}(a), half of the objects accessed in phase 0 are active in the rest phase, and the other half are inactive.
%
Frequently accessed objects in phase 3 are active in phases 7 and 11.
%
When the cache size is larger, it contains more objects, and frequently accessed objects are concentrated.
%
In figure~\ref{fig:wss}(b), frequently accessed objects in phase 0 are active in the rest phase with more accesses(darker color), and the objects in phase 3 are active in phases 5 and 7, which helps to discover the access pattern with cache size.


We categorize objects into four types based on the number of accesses and phases in which they appear. 
%
They are classified as frequently accessed (FA) and infrequently accessed (IA) objects based on their access frequency and divided into multi-phase (MP) and few-phase (FP) objects based on their occurrence across phases.
%
\sys dynamically marks the objects into four types: FA-MP, FA-FP, IA-MP, and IA-FP.
%
It hold FA-MP objects~(\S\ref{ss:filter-hold}), treats FA-FP and IA-MP as suspicious objects~(\S\ref{ss:ghost},\S\ref{ss:dueling}), and filters IA-FP objects.

Figure ~\ref{fig:exapmle} shows how the object type changes in different cache sizes. 
%
For the access \cc{ABCDABEFABACGAH}, if we use footprint four to split the trace, only \cc{A} is an FA-MP object, which is accessed 5 times for 3 phases. 
%
\cc{B} and \cc{C} are FA-FP and IA-MP objects, and others are IA-FP objects. 
%
While if we use footprint six to split the trace, \cc{A}, \cc{B}, and \cc{C} are FA-MP objects. 
%
With this method, the access pahses change with the cache size, and the object types change with the access phases and cache size.
%
To optimize the basic version, we use a sliding window and an appropriate aging function to discover what objects are in the same phase dynamically.
%
In figure~\ref{fig:exapmle}(2), when the footprint is four, there is a request for \cc{E}, we age \cc{A}, \cc{B}, and \cc{C}, and finally we decide to evict \cc{C} in the sliding window.
%
While if the footprint is six and there is a request for \cc{G}, we keep \cc{A}, \cc{B}, and \cc{C} after aging and evict \cc{D} to keep the phase.
%
\sys integrates the sliding window and aging function to the replacement policy only with a few bits as S3-FIFO~(\S\ref{ss:integrate}).



After applying the classification method~(\autoref{ss:split-trace}), we describe the relationship between access patterns and cache size from the perspective of access phases.
%
The more hits within a phase, the more suitable the access pattern is for caching. This also indicates that the cache is relatively large, with a higher hit ratio.
%
In addition to considering an object's access recency and frequency, we need to consider the phases' access distribution.
%
Here come questions: Should we cache the objects in the phase with some accesses or discard the objects in the phase with few accesses?
%
We dynamically adjust the criteria for caching objects based on the overall access information of the cache, in order to adapt to changes in phase characteristics.

\begin{figure}[t]
    \centering
    \subfigure[MRC]{\input{data/fiumrc}}
    \subfigure[Phases for 2MB]{\includegraphics[width=0.47\columnwidth]{fig/fiuwss.png}}
    \caption{Miss ratio and analysis for fiu.\TODO{rewrite MRC without prefetching}}
    \label{fig:fiu}
\end{figure}


The linear-logarithmic relationship exhibits the transformation from FA-MP objects to IA-MP and FA-FP objects when the cache size is reduced.
%
When we analyze the whole workload, the cache size equals the working set size, and there is only one phase.
%
When we reduce the cache size, the number of phases increases, and the frequently accessed (FA) objects are distributed among them.
%
If they are evenly distributed across many phases, they are \cc{FA-MP} objects with many accesses or \cc{IF-MP} objects with few accesses.
%
If they are concentrated in a few phases, they are \cc{FA-FP} objects.
%
In figure~\ref{fig:wss}(a), active objects in phase 0 are IA-MP objects, and the objects in phase 3 are FA-FP objects.
%
%The replacement policy should dynamically adjust the criteria from the phases information to cover the 

Prior work cannot dynamically mark the object types because it is too optimistic about the filter and ghost cache objects.
%
They design replacement policies~\cite{} to retain FA-MP objects while quickly evicting IA-FP objects.
%
For instance, LFU is good at retaining FA objects, while LRU prefers MP objects.
%
However, they do not analyze the object from the whole trace; they only analyze it from the ghost and filter cache, which is insufficient to determine the object type.
%
In figure~\ref{fig:fiu}(a), many policies do not discover the overall access behavior, which hurts the performance even if it enlarges the cache size.
%
LeCaR adjusts the policy based on access to the ghost cache and the fact that their miss ratio waves considerably when the cache size changes.
%
ARC thinks a request hitting the filter or ghost cache is important, so it moves the object to the main cache.

As shown in figure~\ref{fig:fiu}(b), when we analyze the workload with a cache size of 2MB, there are two kinds of phases: one is the phase 0 with a frequently accessed object, and the other is the phase 4 with a few accessed objects.
%
If the cache size is small, phase 0 contains important patterns, and phase 4 contains interference patterns.
%
As we mentioned in~(\autoref{ss:adaption-criteria}), policies store the filtered objects in the ghost cache, so when the cache size is close to 1MB, they can record the objects in phase 4 to the ghost cache.
%
Then, phase 10 repeats the phase 4, and the policies evict the objects in phase 0 to keep the phase 4, leading to a performance drop.
%
\sys integrates the phase information and the access frequency distribution to dynamically adjust the criteria~(\S\ref{ss:integrate}), which filters the objects in phase 4 and keeps the objects in phase 0.
%
With prefetching, \sys outperforms the other policies by about 20\%.
%However, they use static criteria to categorize objects and fail to analyze the type distribution to fit the cache size, leading to huge performance variations with different cache sizes.(\TODO{ figure maybe figure cacheus in fiu, mrc waves})
%
%\sys leverage phase and aging function to hold \cc{FA-FP} objects for a period of time (\S\ref{ss:ghost}) and speculatively retain \cc{IA-MP} objects (\S\ref{ss:dueling}).
%


If the cache size is relatively large, there are too many objects accessed more than once, so we improve the criteria to discover the important objects. 
%
As shown in figure~\ref{fig:fiu}(b), most of the objects are accessed many times, and then here comes repeated access for about 40\% cache size.
%
Many cache replacement policies with a ghost cache can discover it, but they will move all repeatedly accessed objects to the main cache without considering the whole cache.
%
These objects pollute the cache and hurt the performance.
%
It repeats six times in the trace; only a large cache size can discover it and suffer from it.
%
With the access frequency distribution, \sys dynamically increases the number of accesses required for an object to be promoted into the main cache~(\S\ref{ss:integrate}).
%
What's more, \sys leverages the space of the ghost cache to prefetch the objects that are accessed in sequence~(\S\ref{ss:ghost}).


