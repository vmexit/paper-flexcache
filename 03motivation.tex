\section{Motivation}
\label{s:motivation}
Prior work designs the cache replacement policy for a specific access pattern and cache size, but its performance decreases when the access pattern changes or even the cache size varies (\S\ref{ss:performance-policy-change}).
%
We propose a method to split the trace based on the cache size into phases and mark objects into different types according to their popularity in different phases (\S\ref{ss:split-trace}).
%
Based on the phase aware and cache size aware method, we will discuss why we should take the overall cache access behavior into account and design an adaptive cache replacement policy (\S\ref{ss:dynamic-adjust}).
%\sys decides whether to retain an object based on its type and phases information to fit in various cache sizes and access patterns.
%

This section presents why we need a phase aware and cache size aware method to implement a replacement policy (\S\ref{ss:performance-policy-change}), how we implement it (\S\ref{ss:split-trace}), and what to do for adaption (\S\ref{ss:dynamic-adjust}).

\subsection{Performance degradation with different cache size}
\label{ss:performance-policy-change}
Many policies suffer performance degradation when the cache size and access pattern change. 
%
We evaluate XX policies in XX traces with different cache sizes and calculate the relative hit ratio to the the best policy in the policy set.
%
All policies achieve the best performance in a specific cache size and suffer from a tail performance about 20\% to 60\% relative hit ratio to the best policy.
%
Therefore, if we use a specific replacement policy for all traces in the benchmkars, there are xx\% of traces that will lose xx\% performance.
%
What's more even, with the same trace, if we slightly change the cache size without adjusting the replacement policy, more than 5\% of the performance potential may remain unexploited.
%
It is a disaster in the production environments.
%It is common that a designed replacement policy perform well in a specific access pattern, so we should choose a policy for a trace in the production environments.
%

As shown in figure ~\autoref{fig:cloudphysics}, we evaluate the performance of XXX cache replacement policies~\cite{} in Cloudphysics~\cite{}. 
%
CloudPhysics provides XX traces. 
%
We evaluate the hit ratio of XX replacement policies under a given cache size. 
%
For each trace, we select the replacement policy with the highest hit ratio as the optimal policy. 
%
Then, we calculate the performance of each policy relative to the optimal policy and compute the geometric mean across all traces.
%
We observe that S3FIFO performs better when the cache size is small, while LIRS performs better when the cache size is large. 
%
Most replacement policies achieve an average performance of under 95\%, which means that using the same replacement policy for all traces would result in sacrificing nearly 5\% of potential performance gains.
%
While \sys is the best policy in all cache sizes, it is the best policy in xx\% percent of traces.


As shown in figure ~\autoref{fig:cache-size}, ARC~\cite{} and LIRS~\cite{} achieve the best performance in different cache sizes in systor~\cite{}. 
%
We select the replacement policy with the highest hit ratio as the optimal policy and compute the relative hit ratio of each policy to the optimal policy.
%
In figure ~\autoref{fig:cache-size}, when the cache size enlarges from 5GB to 6GB(todo), LIRS is the best policy, and others performance degrade about 5\%.
%
When the cache size is larger than 7 GB to 20BG, QDLP is the best policy.
%
When we take \sys into consideration, it is the best policy and outperforms other policies about 2\%.


%
\begin{figure}[t]
    \centering
    \includegraphics[width=\columnwidth]{fig/demo-cloudphysics}
    \caption{Cache replacement policies' performance with different cache sizes in Cloudphysics.(todo maybe a specific trace or violin plot)}
    \label{fig:cloudphysics}
\end{figure}


\begin{figure}[t]
    \centering
    \includegraphics[width=\columnwidth]{fig/demo-cachesize.pdf}
    \caption{Cache replacement policies' performance with different cache sizes.}
    \label{fig:cache-size}
\end{figure}


\subsection{Phase aware to cache size aware}
\label{ss:split-trace}
To design a cache size aware replacement policy, we analyze the relationship between the cache size and the trace by splitting the trace into phases based on the cache size.
%
Prior work~\cite{} analyzes the trace based on a period of time or a fix numbers of accesses, and when the miss ratio changes, they think there is a phase change.
%
This method reveals that requests for objects change with time, but it is not accurate to adjust the cache replacement policy.
%
We propose that if a set of requests' footprint is equal to the cache size, they are in the same phase.
%

We use this cache size aware method to analyze the trace in Alibaba~\cite{} and find a different way to mark the object types. figure~\ref{fig:wss} \dots
\begin{figure}[t]
    \centering
    \includegraphics[width=\columnwidth]{fig/demo-wss002.png}
    \caption{In different cache sizes, the object types change in Alibaba.}
    \label{fig:wss}
\end{figure}


%According to how many times the object accessed and how many phases it appears, we mark the object into four types dynamicly.  \dots
We categorize objects into four types based on the number of accesses and phases in which they appear. 
%
They are classified as frequently accessed (FA) and infrequently accessed (IA) objects based on their access frequency and divided into multi-phase (MP) and few-phase (FP) objects based on their occurrence across phases.
%
Without a doubt, prior work designs replacement policies~\cite{} to retain FA-MP objects while quickly evicting IA-FP objects.
%
For instance, LFU is good at retaining FA objects, while LRU prefers MP objects.
%
However, they use static criteria to categorize objects and fail to analyze the type distribution to fit the cache size, leading to huge performance variations with different cache sizes.(maybe figure cacheus in fiu, mrc waves)


Figure ~\ref{fig:exapmle} shows the object types changes in different cache sizes. \dots
\begin{figure}[t]
    \centering
    \includegraphics[width=\columnwidth]{fig/demo-exapmle.png}
    \caption{An exapmle for the object types changes in different cache sizes.}
    \label{fig:exapmle}
\end{figure}

\subsection{Dynamicly fit the phase and cache size}
\label{ss:dynamic-adjust}
When the cache size changes, objects are marked as different types, so we must dynamically change the criteria to collect important objects.
%
We analyze all traces and find that only small parts of objects are frequently accessed.
%
In the large cache sizes, most objects are accessed many times, so we need to improve the criteria; otherwise, in the small cache sizes, most objects are accessed a few times, so we need to relax the criteria or even hold suspected objects.

We analyze the trace by counting the times an object is accessed and calculating the average resue time, discovering a linear-logarithmic relationship between them.
%
A small amount of objects are accessed many times, while a large amount are accessed only a few times. 
%
The object accessed frequently has a very short average reuse time, meaning that an object accessed multiple times within a phase is more likely to be important.
%
As figure~\ref{} \dots

If the cache size is relatively large, there are too many objects accessed many times, so we need to improve the criteria to filter out the important objects. \dots (fiu analyze)
%

If the cache size is relatively small, some data may not be accessed until several phases later. We need to speculatively retain these data. \dots (small cache analyze)


