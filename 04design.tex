\clearpage

\section{The \sys Design}
\label{s:design}

Following our approach to identify and classify workload access patterns 
(\autoref{}), this section presents the design of \sys, an efficient cache 
eviction algorithm that adapts to a broad spectrum of access patterns.
%
% This section presents the design goals of \sys (\autoref{ss:design-goals}), an overview of its components and workflow (\autoref{ss:overview}), and a discussion of its limitations (\autoref{ss:discussion-and-limitations}).



\subsection{\sys Components}
\label{ss:components}

\autoref{fig:overview} shows the key components and the workflow of \sys. 
%
We next present the core design of \sys and explain how it meets the design goals~(\S\ref{}). 
%
To facilitate the presentation, we defer the discussion of the performance and 
space optimizations to \autoref{s:impl}. 

%
\DZ{Need to see how we should define metadata}
\DZ{Need to provide a high-level idea of how the algorithm works, especially connect to the access patterns.}
The main part of \sys consists of four FIFO queues: a filter queue~(\ABB{F}), a core queue ~(\ABB{C}), a staging queue~(\ABB{S}), and a ghost queue~(\ABB{G}). 
%
In addition, \sys includes an auxiliary store~(\ABB{AUX}) that stores \XXX{}. 
%
The filter, core, and staging queues record both data and metadata. 
%
The ghost queue and the auxiliary store record only metadata. 

\PN{Task division.}
%
We next explain how \sys divides tasks among components to achieve the overall caching policy (\S\ref{}): screening out cold-rare objects, while retaining the other three types of objects. 

\DZ{Let me know if the term is correct.}
The filter queue is a small queue that quickly \XXX{demotes} likely cold-rare objects, thereby minimizing their residency in the cache.  
%
The core queue consumes most of the cache space to store objects that survive the filter queue. 
%
The ghost queue stores metadata for objects demoted by the filter queue,  serving as a second chance to identify the access patterns of the objects. 
%
This is necessary since the filter queue may falsely filter some objects due to its aggressive, quick demotion policy.
%

The staging queue stores objects 1) evicted from the core queue, and 2) promoted from the ghost queue.
%
Upon object eviction, the staging queue verifies its access 
patterns and reinserts it into the core queue if its access pattern is 
not cold-rare.
%
For objects evicted from the core queue, the staging queue maximizes the 
hit rate by retaining objects with good locality, following the spirit of FIFO-reinsertion~\cite{}.
%
For objects promoted from the ghost queue, the staging queue provides another chance to verify their access patterns before eviction. 


\DZ{Need to explain somewhere that the length of the auxiliary store.}
The auxiliary store operates independently from the aforementioned components. 
%
It records the hotness and popularity of objects to assist \sys in identifying object access patterns. 


\PN{Space allocation.}
%
The filter queue, core queue, and the staging queue use \XXX{}
of the cache place, respectively. 
% 
The ghost queue stores the metadata of one epoch, while the auxiliary store \XXX{}. 
%
We identify these values through sensitivity analysis~(\S\ref{}) and found that they work well across a wide range of real-world workloads. 

\DZ{Key invairant: observe the access of the data for one epoch.}
\subsection{\sys Workflow}
\label{ss:workflow}

\PN{Overview.}
%
As shown in \autoref{}, for each object accessed for the first time, \sys places the object into the filter queue and observes its access pattern with the help of the auxiliary store.
%
Upon eviction from the filter queue, depending on its access pattern, \sys either promotes the object to the core queue (for hot or popular objects), or evicts the object but records its metadata in the ghost queue (offering a second chance to classify its access patterns as discussed in \S\ref{}).

An object that enters the core queue will later be evicted to the staging queue.
%
Upon eviction from the staging queue, \sys reexamines the object's access pattern, and only evicts it if is cold and rare. 
%
Otherwise, \sys reinserts the object into the core queue.

For an object in the ghost queue, upon access, \sys must bring it back into the cache.
%
Specifically, \sys reexamines the object's access pattern and promotes it to the main queue if it is hot or popular.
%
Otherwise, \sys promotes it to the staging queue. 
%
In the latter case, if the object is evicted from the staging queue, \sys places it back in the ghost queue, ensuring that \sys observes the object's access pattern for a full epoch. 

\XXX{The auxiliary store operates}

We next present the detailed algorithm of \sys in \autoref{}. 

\PN{Recording objects' hotness and popularity.}
%
For each incoming object, regardless of whether it results in a cache hit or miss, \ABB{AUX} records \XXX{}

%its hotness. 

\PN{Cache hits.}
%
Upon a cache hit~(\ie, the object resides in one of the \ABB{F}, \ABB{C}, or \ABB{S} queues), \sys simply updates the hotness of the object~(L\XXX{}),  which will later be used to \XXX{}

\PN{Cache misses.}
%
\DZ{Lines 8 and 10 should have comments stating cache hits or miss.}
%
Upon a cache miss (L\XXX{}), \sys first checks if the cache is full, and if so, evicts an object~(L\XXX{}).
%
Next, \sys checks if the object has been previously encountered and resides in the ghost queue~(L\XXX{}).
%
If not, \sys treats the object as a new object and inserts it into the filter queue~(L\XXX{}).
%
Otherwise, \sys checks the object's access pattern~(L\XXX{}-\XXX{}) and inserts it into either the core queue~(L\XXX{}) or the staging queue~(L\XXX{}). 

\PN{Object eviction.}
%
When the cache is full, \sys first tries to evict from the filter queue (L\XXX{}). 
%
If no object can be evicted~(due to \eg, all objects evicted from the filter queue go to the core queue), \sys first evicts objects from the core queue to the staging queue~(L\XXX{}). 
%
Next, \sys evicts objects from the staging queue~(L\XXX{}).
%
Such an eviction guarantees to succeed since \XXX{}. 
%
As discussed earlier, for an evicted object coming from the ghost queue, 
\sys inserts it back~(L\XXX{}-\XXX{}). 




\subsection{Adapting to Various Access Patterns}

\PN{Hotness and Popularity Thresholds.}
%
\autoref{} presents \syss adaptive algorithm. 
%
Departing from prior work that uses \XXX{} to achieve adaptiveness~(\S\ref{}), 
%
\syss adaptiveness is enabled by its use of dynamic thresholds to classify 
an object's access pattern. 
%
An object is hot (and popular, respectively) if its \XXX{} exceeds the hotness (and popularity) threshold~(L\XXX{} in \autoref{}).

\DZ{How does changing the thresholds adapt to different access patterns?}
Intuitively, a higher hotness thresholds results in fewer objects being classified as hot, thereby \XXX{}. 

\PN{Self-tuning the thresholds based on the cache size.}
\XXX{Motivate why doing this.}
%

\XXX{Switch to implementationn from this point now.}
To decide the hotness threshold, \sys maintains in the auxiliary store 
the distribution of hotness counters~(\ie, how many cached objects fall under each specific \XXX{counter} value)~(L\XXX{}). 
%
\XXX{When does it got updated?}
\XXX{How do we decide the popularity threshold?}

\PN{Adapting to different access patterns.}
\XXX{Perhaps list one trace that S3FIFO does not perform well and argue that 
how \sys adapts to it}












\PN{Adaptiveness.}
%


For example, repeated accesses~(Churn) have a good locality, but they will pollute cache if cache cannot hold them all.
%
If cache could hold all of them, they are \textit{frequent-persistent} data and stay in \ABB{M}.
%
If cache cannot hold all of them and \ABB{G} could observe the repeatness, \sys takes part of them as \textit{frequent-ephemeral} data in \ABB{M}, and then \ABB{H} gradually raises the hotness threshold to block other \textit{infrequent-persistent} data.
%
If \ABB{G} cannot observe the repeatness, \sys guesses part of them to \ABB{S} with the help of \ABB{K}.



\section{Implementation}
%
\DZ{Where do we implement it? Lines of code to report?}

\DZ{How do we immplement the FIFO queues, ghost queues, and K?}
The storage logic leverages a hash table to index the position of data, which is efficiency and scalable.

A FIFO-based queue in evcition algorithm logic has linked-list or ring-buffer implementation.
%
With linked-list implementation, linked-list pointers can intergate with storage logic with a hook portabliy, but have to manage pointers with atomic operations, which reduces scalability.
%
Ring-buffer implementation is more scalable with less atomic operations, but it requires extra space for the buffer, which also wastes space when workload has many \textit{delete} operations.

\ABB{G} can be further simplified for efficiency and scalability.
%
Since \ABB{G} will not delete data except for eviction~(\BC{6}), it has less operations and space overhead in both linked-list and ring-buffer implementations.
%
An accurate \ABB{G} can be used for prefetching~(\TODO{ref}), while a lossy \ABB{G} can instead evcition algorithm logic with a timestamp and fingerprint field.
%
For example, a fingerprint has 4 Byte of hashed key and a timestamp has 4 Byte of insertion time.
%
\sys stores a scope of timestamps based on the epoch size and evicts data beyond the scope.

\ABB{K} with a forget function has many candidate implementations, which are scalable.
%
A Counting Bloom Filter (CBF)~\cite{} increases all the indexed counters when recording data with less space overhead and false positives.
%
A Count-Min Sketch (CMS)~\cite{} only increases the minimum indexed counter, which reduce false positives.
%
A sliding window sketch~\cite{} provides various forget functions, which separates \ABB{K} into many sub-sketches for different epochs.
%
At the beginning of a new epoch, it inserts records into a new sub-sketch and forgets the oldest sub-sketch beyond many epochs.
%
To improve the space utility, \ABB{K} is a sketch and clean a fraction of counters with a forget function periodically.
%
A fine-grained forget function ages counters one by one after a fixed number of inserations, which averages the operation overhead for efficiency.

\subsection{Overhead Analysis}

\textbf{Computation overhead.} 
%
\sys does not introduce extra computation overhead as prior work~\cite{}.
%
With a maximum value for hotness counter and delayed type checking, \sys thus performs negligible metadata updates on cache hits.
%
When cache miss occurs, \sys checks data in \ABB{S} gradually as prior work~\cite{}, and hotness distribution can be updated lock-free using atomic operations.
%
Hash function is used widely in basic operations and \ABB{K}, while xxHash provides 31.5 GB/s operations~\cite{}, which is not a bottleneck for the performance.
%

\textbf{Space overhead.} 
%
\sys introduces space overhead for metadata and components \ABB{G} and \ABB{K}.
%
\sys uses 3 bits to store the access frequency, which is sufficient for most workloads.
%
With a bit for suspection, the 4 bits can often be piggybacked on the unused flags in the metadata.
%
\ABB{G} stores the same number of data (only metadata) as the total size of other queues.
%
Assuming the average object size is 4KB, and the object id is 4 bytes, \ABB{G} uses 0.1\% of the total memory space.
%
In Count-Min Sketch~\cite{}, with a false positive error rate of 1\% and error range of 1, a 8-epoch \textit{infrequent-persistent} data requires about 3 bits for record.
%
\ABB{K} comsumes about 0.13\% of the total memory space.
%, and there are 40.5 bits for each object.
%the space amplification is about 13.5.



\subsection{Discussion and Limitations}
\label{ss:discussion-and-limitations}


\textbf{Online Adaption.} 
%
\DZ{One should change the sizes of components to adapt to different access patterns, but we didn't due to \XXX{}}
\sys integrates online epoch and hotness analysis with cache size to adapt to various access patterns.
%
With different cache sizes, data experiences different epoch sizes in \ABB{M} and \ABB{G}, and hotness threshold changes with epoch.
%
Therefore, to adjust the epoch size and hotness threshold, it is convenient to change the size of \ABB{M} and \ABB{G} and the target portion.
%

However, there is not a proper theoretical model to guide the adjustment of components size with changed types.
%
There are some theoretical models for fixed classification into different components, which generate the MRC of each components and optimize the overall hit ratio~\cite{}.
%
Therefore, we leave the adaption of \sys to future work and use fixed sizes for all the components in this paper.
%
The \ABB{F} is 10\% of the cache size, \ABB{S} is 5\%, and \ABB{M} is about 85\%.
%


\textbf{Prefetching.} \sys can prefetch in \ABB{G} for \textit{infrequent-empheral} data or integrate with other prefetchers.
%
A typical \textit{Churn} pattern has a sequence of accesses, while \ABB{K} would not cover all of them for limited space.
%
As discussed in \autoref{ss:overview}, \ABB{G} also keeps the relative access order for epoch awareness, which provides an opportunity for prefetching.
%
When continueous data is accessed in \ABB{G}, \sys can prefetch the following data in the sequence to \ABB{F} and maintain metadata in \ABB{G}.
%
If prefetching hits in \ABB{F}, it would be treated as normal data; otherwise, \sys will evict it.
%
When \sys intergates with other prefetchers, \sys can leverage the prefetcher to insert data into \ABB{F} directly, which will not affect other queues.

\textbf{Limitations.}
%
On workloads with tiny objects, linked-list implementation of FIFO queues would introduce high space overhead for pointers.
%
\ABB{G} and \ABB{K} would also introduce high space overhead for metadata, and \sys needs to limit their sizes.
%

\textbf{Adversarial workloads for \sys.}
%
\sys highly relies on epoch and hotness analysis to identify access patterns.
%
(1) Workloads with large reuse which apporaches the epoch size are challenge for epoch analysis.
%
The large reuse would have many hits in \ABB{G} rather than \ABB{M} for the first epoch in \sys, and it will be evicted by suspected data in \ABB{S} at the end of the epoch, leading to many misses.
%
(2) Workloads with greatly changed hotness distribution are challenge for hotness analysis.
%
In this case, the hotness threshold would change frequently, and \ABB{K} takes time to learn it. 
%


Other algorithms also suffer from these workloads, and large cache size or prefetcher can mitigate the influence.
%
Algorithms with a small filter queue~(S3-FIFO~\cite{}, 2Q~\cite{}) also evict data to ghost queue, leading to misses.
%
Algorithms without a sketch~(ARC~\cite{},CACHEUS~\cite{}) also discard useful data due to limited accesses.
%
With large cache size, algorithms can catch marginal accesses.
%
Most of equal hotness counters come from repeated accesses in a sequence, and prefetchers can help to catch them.
%



\begin{figure}[t]
    \centering
    \includegraphics[width=\columnwidth]{fig/overview.drawio.pdf}
    \caption{Overview for \sys. Cache space consists of five parts: filter cache, main cache, suspicious cache, ghost cache, and CBF. The workflow has three major parts, (1)cache promotion and eviction in four sub-cache. (2)IA-MP objects in the filter cache duels with the tail object in the suspicious cache with CBF. (3)Leverage the metadata in the ghost cache to find FA-FP objects and prefetch sequence accessed objects.\TODO{update}}
    \label{fig:overview}
\end{figure}

\subsection{Properties}
\label{ss:properties}

\syss design achieve the following important properties mentioned in prior cache literature~\cite{}.

% \PN{Cover a wide range of access patterns.}

\PN{Self-adaptive parameters.}
Tuning parameters is notoriously difficult for cache eviction algorithms~\cite{}.

\PN{Lazy promotion and quick demotion.}
%
Recent advances in cache eviction algorithms~\cite{} have shown that lazy promotion and quick demotion can effectively improve cache performance.

\PN{Multicore scalability.}
%
Many Modern cache replacement algorithms are built with cache primitives, such as FIFO queues and LRU~\cite{}.
%
\sys uses FIFO queues to achieve multicore scalability.