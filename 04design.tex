\clearpage

\section{The \sys Design}
\label{s:design}

Following our approach to identify and classify workload access patterns 
(\autoref{}), this section presents the design of \sys, an efficient cache 
eviction algorithm that adapts to a broad spectrum of access patterns.
%
% This section presents the design goals of \sys (\autoref{ss:design-goals}), an overview of its components and workflow (\autoref{ss:overview}), and a discussion of its limitations (\autoref{ss:discussion-and-limitations}).



\subsection{\sys Components}
\label{ss:components}

\autoref{fig:overview} shows the key components and the workflow of \sys. 
%
We next present the core design of \sys and explain how it meets the design goals~(\S\ref{}). 
%
To facilitate the presentation, we defer the discussion of the performance and 
space optimizations to \autoref{s:impl}. 

%
\DZ{Need to see how we should define metadata}
\DZ{Need to provide a high-level idea of how the algorithm works, especially connect to the access patterns.}
The main part of \sys consists of four FIFO queues: a filter queue~(\ABB{F}), a core queue ~(\ABB{C}), a staging queue~(\ABB{S}), and a ghost queue~(\ABB{G}). 
%
In addition, \sys includes an auxiliary store~(\ABB{AUX}) that stores \XXX{}. 
%
The filter, core, and staging queues record both data and metadata. 
%
The ghost queue and the auxiliary store record only metadata. 

\PN{Task division.}
%
We next explain how \sys divides tasks among components to achieve the overall caching policy (\S\ref{}): screening out cold-rare objects, while retaining the other three types of objects. 

\DZ{Let me know if the term is correct.}
The filter queue is a small queue that quickly \XXX{demotes} likely cold-rare objects, thereby minimizing their residency in the cache.  
%
The core queue consumes most of the cache space to store objects that survive the filter queue. 
%
The ghost queue stores metadata for objects demoted by the filter queue,  serving as a second chance to identify the access patterns of the objects. 
%
This is necessary since the filter queue may falsely filter some objects due to its aggressive, quick demotion policy.
%

The staging queue stores objects 1) evicted from the core queue, and 2) promoted from the ghost queue.
%
Upon object eviction, the staging queue verifies its access 
patterns and reinserts it into the core queue if its access pattern is 
not cold-rare.
%
For objects evicted from the core queue, the staging queue maximizes the 
hit rate by retaining objects with good locality, following the spirit of FIFO-reinsertion~\cite{}.
%
For objects promoted from the ghost queue, the staging queue provides another chance to verify their access patterns before eviction. 


\DZ{Need to explain somewhere that the length of the auxiliary store.}
The auxiliary store operates independently from the aforementioned components. 
%
It records the hotness and popularity of objects to assist \sys in identifying object access patterns. 


\PN{Space allocation.}
%
The filter queue, core queue, and the staging queue use \XXX{}
of the cache place, respectively. 
% 
The ghost queue stores the metadata of one epoch, while the auxiliary store \XXX{}. 
%
We identify these values through sensitivity analysis~(\S\ref{}) and found that they work well across a wide range of real-world workloads. 

\DZ{Key invairant: observe the access of the data for one epoch.}
\subsection{\sys Workflow}
\label{ss:workflow}

\PN{Overview.}
%
As shown in \autoref{}, for each object accessed for the first time, \sys places the object into the filter queue and observes its access pattern with the help of the auxiliary store.
%
Upon eviction from the filter queue, depending on its access pattern, \sys either promotes the object to the core queue (for hot or popular objects), or evicts the object but records its metadata in the ghost queue (offering a second chance to classify its access patterns as discussed in \S\ref{}).

An object that enters the core queue will later be evicted to the staging queue.
%
Upon eviction from the staging queue, \sys reexamines the object's access pattern, and only evicts it if is cold and rare. 
%
Otherwise, \sys reinserts the object into the core queue.

For an object in the ghost queue, upon access, \sys must bring it back into the cache.
%
Specifically, \sys reexamines the object's access pattern and promotes it to the main queue if it is hot or popular.
%
Otherwise, \sys promotes it to the staging queue. 
%
In the latter case, if the object is evicted from the staging queue, \sys places it back in the ghost queue, ensuring that \sys observes the object's access pattern for a full epoch. 

\XXX{The auxiliary store operates}

We next present the detailed algorithm of \sys in \autoref{}. 

\PN{Recording objects' hotness and popularity.}
%
For each incoming object, regardless of whether it results in a cache hit or miss, \ABB{AUX} records \XXX{}

%its hotness. 

\PN{Cache hits.}
%
Upon a cache hit~(\ie, the object resides in one of the \ABB{F}, \ABB{C}, or \ABB{S} queues), \sys simply updates the hotness of the object~(L\XXX{}),  which will later be used to \XXX{}

\PN{Cache misses.}
%
\DZ{Lines 8 and 10 should have comments stating cache hits or miss.}
%
Upon a cache miss (L\XXX{}), \sys first checks if the cache is full, and if so, evicts an object~(L\XXX{}).
%
Next, \sys checks if the object has been previously encountered and resides in the ghost queue~(L\XXX{}).
%
If not, \sys treats the object as a new object and inserts it into the filter queue~(L\XXX{}).
%
Otherwise, \sys checks the object's access pattern~(L\XXX{}-\XXX{}) and inserts it into either the core queue~(L\XXX{}) or the staging queue~(L\XXX{}). 

\PN{Object eviction.}
%
When the cache is full, \sys first tries to evict from the filter queue (L\XXX{}). 
%
If no object can be evicted~(due to \eg, all objects evicted from the filter queue go to the core queue), \sys first evicts objects from the core queue to the staging queue~(L\XXX{}). 
%
Next, \sys evicts objects from the staging queue~(L\XXX{}).
%
Such an eviction guarantees to succeed since \XXX{}. 
%
As discussed earlier, for an evicted object coming from the ghost queue, 
\sys inserts it back~(L\XXX{}-\XXX{}). 




\subsection{Adapting to Various Access Patterns}

\PN{Hotness and Popularity Thresholds.}
%
\autoref{} presents \syss adaptive algorithm. 
%
Departing from prior work that uses \XXX{} to achieve adaptiveness~(\S\ref{}), 
%
\syss adaptiveness is enabled by its use of dynamic thresholds to classify 
an object's access pattern. 
%
An object is hot (and popular, respectively) if its \XXX{} exceeds the hotness (and popularity) threshold~(L\XXX{} in \autoref{}).

\DZ{How does changing the thresholds adapt to different access patterns?}
Intuitively, a higher hotness thresholds results in fewer objects being classified as hot, thereby \XXX{}. 

\PN{Self-tuning the thresholds based on the cache size.}
\XXX{Motivate why doing this.}
%

\XXX{Switch to implementationn from this point now.}
To decide the hotness threshold, \sys maintains in the auxiliary store 
the distribution of hotness counters~(\ie, how many cached objects fall under each specific \XXX{counter} value)~(L\XXX{}). 
%
\XXX{When does it got updated?}
\XXX{How do we decide the popularity threshold?}

\PN{Adapting to different access patterns.}
\XXX{Perhaps list one trace that S3FIFO does not perform well and argue that 
how \sys adapts to it}


\PN{Adaptiveness.}
%
For example, repeated accesses~(Churn) have a good locality, but they will pollute cache if cache cannot hold them all.
%
If cache could hold all of them, they are \textit{frequent-persistent} data and stay in \ABB{M}.
%
If cache cannot hold all of them and \ABB{G} could observe the repeatness, \sys takes part of them as \textit{frequent-ephemeral} data in \ABB{M}, and then \ABB{H} gradually raises the hotness threshold to block other \textit{infrequent-persistent} data.
%
If \ABB{G} cannot observe the repeatness, \sys guesses part of them to \ABB{S} with the help of \ABB{K}.

\subsection{Properties}
\label{ss:properties}

\syss design achieve the following important properties mentioned in prior cache literature~\cite{}.

% \PN{Cover a wide range of access patterns.}

\PN{Self-adaptive parameters.}
Tuning parameters is notoriously difficult for cache eviction algorithms~\cite{}.

\PN{Lazy promotion and quick demotion.}
%
Recent advances in cache eviction algorithms~\cite{} have shown that lazy promotion and quick demotion can effectively improve cache performance.

\PN{Multicore scalability.}
%
Many Modern cache replacement algorithms are built with cache primitives, such as FIFO queues and LRU~\cite{}.
%
\sys uses FIFO queues to achieve multicore scalability.

\PN{Explainable behavior.}
%
Argue this is how we are better than machine learning? 




\section{Realizing \sys}
% 
We implemented \sys in both \cachelib~\cite{}, a development library for caching systems deployed at Facebook, and \libcachesim~\cite{}, an efficient cache simulator. 
%
We choose these two frameworks to benefit from that many eviction algorithms~(\S\ref{}) are already implemented on them.
%
We also contributed to \cachelib an implementation of \arc and \car, and \libcachesim an implementation of \car, respectively.  


\PN{Minimizing the auxiliary store.}
%
A practical implementation of \sys must minimize the space overhead incurred by the auxiliary store.
%
The main overhead is that the auxiliary store records the access counts of each object in the past \XXX{} epochs. 
%
A naive implementation that records the object names~(\eg, block/page addresses, keys of key-value pairs) and \XXX{} counters would incur large overhead.

Following \wtinylfu~\cite{}, \sys minimizes the aforementioned overhead using 
a count-min sketch~\cite{} with a sliding window. 
%
A count-min sketch operates similar to a bloom filter~\cite{} (more specifically, a counting bloom filter~\cite{}), where it is equipped with multiple, say \ABB{H}, hash functions. 
%
A count-min sketch maintains a two-dimensional array where the number of rows equals the number of hash functions~(\ie, \ABB{H}), and the number of columns represents the tradeoff betwen space and accuracy.
%
When an item arrives, it is hashed by each hash function, where each hash function maps the item to a specific column in its corresponding row.
%
The counters of these \ABB{H} cells are incremented. 
%
Upon query, the minimum of the \ABB{H} counters mapped by the hash functions is returned as the estimated count of the item.
%
Therefore, a count-min sketch forgos the need to store each object's name. 

In addition, rather than using a count-min sketch for each epoch, \sys uses only a single sketch. 
%
This is because multiple sketches incur space and performance overhead (since one must query all sketches to obtain the total access counts across all epochs).
%
To ensure that the sketch approximates the access counts in the past \XXX{} epochs, \sys periodically halves all counters in the sketch.  
%
\sys maintains a global counter which got incremented upon each item arrival. 
%
Once the global counter reaches a threshold, \sys halves the global counter and all the counters in the sketch.
%
\wtinylfu~\cite{} shows that this approach is reasonably accurate, supported by both theoretical guarantees on its error bounds and evaluation results. 









% For simplicity, we implement \ABB{K} with a sketch structure with a forget function.
% %
% In the sketch, each object maps a counter with a hash function.
% %
% To simulate the sliding window sketch~\cite{}, \ABB{K} has a global counter and a global indexer for forget function.
% %
% Once inserting an object, \ABB{K} increases the global counter and increases mapped counter for the object.
% %
% When the global counter reaches a threshold~(\eg 8), \ABB{K} halves the counter pointed by the global indexer to forget old records, and then increases the global indexer and resets the global counter for the next counter.
% %
% On average , each insertion only halves $1/threshold$ counters for 2 thresholds' epochs.



% Cite a large number of papers that is implemented with CacheLib; systems 
% reviewers might doubt the simulation.
% Following much prior work~\cite{}, we evaluate \XXX{latency} and \XXX{throughput} in \cachelib~(\S\ref{}) and hit ratio in \libcachesim~(\S\ref{}). 
% %

\PN{Common optimizations.}
%
\sys applies several common performance and space optimizations in prior work. 
%
First, following the existing implementation in \cachelib, \sys uses a hash table to index all cached objects to minimize the lookup time.

Second, following~\cite{}, \sys implements the ghost queue with a hash table. 
%
For each ghost object, \sys stores in the hash table its fingerprint, \hotness counter, and a sequence number, for a total of 8 bytes.
%
\sys uses the sequence number to identify if an object is still in the ghost queue, facilitating lazy object deletion.
%
\sys increments a global sequence number upon each insertion to the ghost queue. 
%
Thus, any object with a sequence number less than the global sequence number minus ghost queue's size has already evicted from the ghost queue.
%
Thanks to the sequence number, \sys lazily removes an evicted ghost object from the hash table only upon its access. 

\PN{Other optimization/implementation.}
%
\sys uses three bits to store the \hotness counter and uses \XXX{} hash for all relevant hash tables/count-min sketch. 
%
\syss current implementation uses a linked list to implement the FIFO queues~(\ie, \XXX{the filter, core, and staging} queues), while one can also implement these queues with ring buffers.  
%

\DZ{Modify the pseudocode to make this part more understandable}
Another optimization in \sys is that it does not delete the object from the ghost queue upon its promotion to the staging queue~(L\XXX{} in \autoref{}).
%
Therefore, \sys does not need to record each object's position in the ghost queue~(L\XXX{}). 
%
This is possible since a stale object in the ghost queue does not affect the correctness of \sys; 
%
\sys only checks if the object is in the ghost queue upon a cache miss~(L\XXX{}), where the object must not be in the staging queue.  

\PN{Tradeoff between cache hit rates and overhead.}
%
Using a count-min sketch for recording objects' popularity and a hash table for the ghost queue may reduce the hit rates of \sys. 
%
In the former case, multiple objects may map to the same counter and the reset operation is an estimation. 
%
In the latter case, \sys may mistakenly view an object in the ghost queue due to fingerprint collisions.
%
However, our evaluation shows that \XXX{}. 



\subsection{Overhead Analysis}
%
\XXX{detailed evaluation in \S\ref{}}


\PN{Computation overhead.} 
%
Upon a cache access, \sys searches the object in the hash table. 
%
A cache hit only requires updating the \hotness counter~(L\XXX{} in \S\ref{}) and the \hotness map, incurring minimal overhead. 
%
On a cache miss, most of the processing time comes from evicting items from the filter or staging queues
%
Both cases involve inserting objects from the filter queue to the main queue~(L\XXX{}), and the latter case requires inserting objects from the staging queue to the main queue~(L\XXX{}).
%
However, in practice, such reinsertions are rare since \XXX{}. 
%
The rest of the operations (\eg, \XXX{}) incur minimal overhead.


\PN{Multicore scalability.}
%
\PN{Update on the hotness: atomic increment.}
\PN{FIFO queues}
\PN{Hash table.}
\PN{Maintaining the metadata of \sys: hotness distribution.}



\PN{Space overhead.} 
%
The space overhead of \sys mainly comes from 1) per-object metadata and 2) the ghost queue; and 3) the auxiliary store.
%
Each metadata is 4 bits, consisting of a \hotness counter~(3 bits) and a 1-bit flag recording if the object is from the ghost queue~(L\XXX{} in \S\ref{}).
%
The ghost queue stores the same amount of objects as the main cache, and each object consumes an additional of 8 bytes. 
%
The count-min sketch in the auxiliary store uses \XXX{} bytes (\XXX{Row, Column, and Count bits}).
%
\XXX{map overhead, epoch counter, globalk counter} 

Consider a typical object size of 4KB, the space overhead of \sys is \XXX{}. 


\subsection{Discussion}
\label{ss:discussion-and-limitations}

\XXX{Relationship with respect to S3FIFO: move this to the evaluation.}

\PN{Adapting component size.}
%
While \syss current design partitions the cache into fixed portions for the filter, main, and staging queues, 
%
we note that dynamically adjusting the sizes of these components further enhances \syss adaptiveness.  
%

The size of the filter queue determines the duration for which a new object remains in the cache;
%
a larger filter queue increases the chances of a new object being stayed in 
the cache, thereby improving performance if new objects exhibit 
good locality. 
%
However, if new objects exhibit poor locality, a larger filter queue may waste cache space on them, reducing performance. 
%
The staging queue captures the same tradeoff for an object that was accessed before but is still classified as cold and rare in the ghost queue (since such objects are promoted to the staging queue upon access, see \XXX{} in 
\autoref{}).
%

We find that adaptively adjusting component sizes remains relevant, 
since tuning the sizes of the filter and staging queues can help \sys handle certain adversarial workloads, as detailed next.
%
Our view on the poor performance of existing size-adaptive algorithms~(\S\ref{}) is that they lack a theoretical model to guide the adaptation.
%
%There are some theoretical models for fixed classification into different components, which generate the MRC of each components and optimize the overall hit ratio~\cite{}.
As future work, we plan to follow \XXX{} to develop a theoretical model for size adaptation. 

\PN{Adversarial workloads for \sys.}
%
The remaining adversarial workloads for \sys fall into two categories: (1) those whose past access patterns do not predict future ones, and (2) those that goes against \syss fixed size cache partitioning.
%

For the first category, we observe traces that repeatedly alternate between two phases: a) accessing a large number of objects once (\ie, the scan pattern), and b) repeatedly accessing a small set of hot objects. 
%
However, the hot objects in the second phase differ in each iteration.
%
In this case, \sys fails to identify the hot objects in the second phase, as there is little prior indication of their hotness.

For the second category, we find traces that access most objects twice, with 
the interval between the two accesses slightly exceeding \syss filter queue 
size.
%
This causes \sys to evict most objects before their second access, leading to poor performance.
%
A larger cache or adaptively adjusting the filter queue size, as discussed earlier, can avoid this issue. 

We note that other adaptive algorithms also struggle with \syss adversarial workloads.
%
The first category breaks an inhernt assumption of all adaptive algorithms~(\ie, using the past to predict the future). 
%
The second category, as reported in~\cite{}, is generally challenging for all algorithms that partitions cache spaces, including both adaptive ones~(\eg, \arc, \car, \cacheus, and \lecar) and non-adaptive ones~(\eg, \sthreefifo, \wtinylfu, and \lirs).

\PN{Complexity.}
%
The complexity of \sys is modest.
%
\DZ{Can we make such an argument?}
% its complexity is comparable to other state-of-the-art adaptive algorithms such as \arc~\cite{} and \car~\cite{}.
While \sys is more complex than algorithms like \lru, \lfu, and \sieve~\cite{} 
due to its use of multiple components, we argue that \sys is simpler than machine-learning-based algorithms such as \XXX{}. 
% 
In addition, the complexity does not translate to high overhead, as discussed 
in \S\ref{}, and we found that \syss behavior is easy to reason 
about~(\S\ref{}) thanks to its intuitive pattern 
characterization~(\S\ref{}) and clean task division among components~(\S\ref{}).






\begin{figure}[t]
    \centering
    \includegraphics[width=\columnwidth]{fig/overview.drawio.pdf}
    \caption{Overview for \sys. Cache space consists of five parts: filter cache, main cache, suspicious cache, ghost cache, and CBF. The workflow has three major parts, (1)cache promotion and eviction in four sub-cache. (2)IA-MP objects in the filter cache duels with the tail object in the suspicious cache with CBF. (3)Leverage the metadata in the ghost cache to find FA-FP objects and prefetch sequence accessed objects.\TODO{update}}
    \label{fig:overview}
\end{figure}

