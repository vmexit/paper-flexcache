\section{Cache Eviction Algorithms}
\label{s:background}

Software caches are widely deployed in modern systems software to improve performance. 
%
\DZ{Find 8-9 citations for each example below.}
For example, data centers often leverage key-value stores~(\eg, Memcached~\cite{}, Redis~\cite{}) as in-memory caches~\cite{}. 
%
% Ask Zonghao for the citations here.
Almost all modern operating systems use page caches to speed up file 
system operations~\cite{}.
%
Content delivery networks (CDNs)~(\eg, Akamai~\cite{}) cache data on edge servers that are close to end users, thereby minimizing access latency~\cite{}. 

The efficiency of any cache system hinges on its eviction algorithm, since it decides which objects\footnote{We use the term ``object'' to collectively refer to various types of data stored in a cache.} stay in the scarce cache space. 
%
This section provides background on cache eviction algorithms by discussing their key performance metrics~(\S\ref{}) and surveying the state of the art~(\S\ref{}).
%


\subsection{Desired Properties of Cache Eviction Algorithms}
%

\PN{High hit rate.} 
%
Hit rate is arguably the most important metric for an eviction algorithm.  
%
This is because backend storage is often orders of magnitude slower than the cache (consider, \eg, DRAM: access latency 100s of ns vs. SSD: access latency 10s-100s of $\mu$s).
%
Therefore, even a small improvement in hit rate leads to significant end-to-end performance gains.


\PN{Low latency and high throughput.}
%
A high hit rate does not necessarily imply low latency nor high throughput, since an eviction algorithm may incur high operation overhead per access~(\eg, lookup and metadata maintenance). 
%
Thus, an eviction algorithm should minimize such operation overhead.  


\PN{Multicore Scalability.}
%
\DZ{I guess cite some Juncheng Yang's work below and perhaps some other works}
Multicore scalability is increasingly important for modern cache systems, 
which exploit multiple cores to handle large volumes of requests~\cite{}.  
%
With today's servers often equipped with hundreds of CPU cores, an eviction algorithm must avoid scalability bottlenecks to benefit from such parallelism.

\subsection{Evolution of Cache Eviction Algorithms}

\subsubsection{Static Eviction Algorithms}
%
A static algorithm employs a fixed set of rules to perform eviction at all times.
%
Dating back to \XXX{}, early static algorithms, \eg, \lfu~\cite{}, \fifo~\cite{}, and \lru~\cite{}, are based on simple heuristics that work well for specific access patterns.
%
For example, \lru favors an access pattern with high recency, but causes thrashing in scan patterns~(consider, \eg, sequentially accessing a large file).
%

Follow-up work aims to make static algorithms more robust across diverse access patterns.   
%
One thrust of the work, such as \lirs~\cite{} and \lhdc~\cite{}, uses better metrics to rank objects for eviction (rather than, \eg, ranking them by their most recent access, as in \lru).
%
Another thrust of the work, such as \sthreefifo~\cite{} and \twqueue~\cite{}, leverages multiple components to improve performance.  
%
For example, \sthreefifo uses three FIFO queues, where one short queue quickly demotes objects accessed only once, thereby effectively handling patterns such as scan. 
%
Algorithms, such as \wtinylfu~\cite{}, combine the above two thrusts. 
%
Finally, recent developments in machine learning have led to algorithms that leverage it to predict objects for eviction~\cite{}. 

However, despite their elegant designs, existing static algorithms still struggle to handle the diverse access patterns of modern workloads~(\S\ref{}). 

\subsubsection{Adaptive Eviction Algorithms}

An adaptive eviction algorithm involves 1) observing and characterizing workload access patterns and 2) adjusting its behavior accordingly~(by, \eg, automatically tuning internal parameters) to maximize performance. 
%
Such adaptiveness promises to make adaptive algorithms \XXX{}.  


Adaptive algorithms fall into two categories: 1) size-adaptive ones and 2) policy-adaptive ones.
%

\PN{A size-adaptive algorithm} partitions the cache into multiple parts and adapts by adjusting each part's size based on access patterns.
%
Representative examples include \arc~\cite{} and \car~\cite{}, both of which follow the principle of dynamically balancing recency and frequency.
%
\arc divides the cache into two LRU lists: a recency list~(that tracks recently accessed objects) and a frequency list~(that tracks frequently accessed objects).
%
A newly accessed object is first placed in the recency list and enters the frequency list upon a second access.
%
Upon a cache hit, \arc increases the size of the corresponding list~(and decreases the size of the other list), thereby favoring recency or frequency based on the current access pattern.
%
\car follows a similar design but replaces the LRU lists with FIFO queues. 

\PN{A policy-adaptive algorithm} adapts by switching between multiple base eviction algorithms according to their effectiveness under observed access patterns.
%
\cacheus~\cite{} and \lecar~\cite{} are the state of the art. 
%
Both works use two base eviction algorithms and maintain a weight for each. 
%
Upon a cache miss, they select one base algorithm to perform the eviction with probabilities proportional to the weights.
%
Next, they check whether a wrongful eviction has occurred by determining whether the wanted object appears in the eviction history of either base algorithm.
%
If so, they penalize the corresponding algorithm by decreasing its weight. 
%
Finally, both \cacheus and \lecar use machine learning to control the rate at which weights change.
%





\section{How Modern Cache Workloads Behave}
\label{s:motivation}

\subsection{Characteristics of Modern Cache Workloads}

\DZ{Make the case that most modern cache workloads are diverse and evolving.}

\PN{Diverse Access Patterns.}
%
Prior work classifies access space into several primitive patterns, including \textit{LFU-friendly}, \textit{LRU-friendly}, \textit{Churn}, and \textit{Scan}~\cite{}.
%
There are also \textit{One-hit wonder}~\cite{} and \textit{Inter-Reference Recency}~\cite{} patterns.
%
Real-world workloads are often a complex mixture of these primitive access patterns with different contributions.

\PN{Evolving Access Patterns.}
%
With the time passing, the access pattern of a workload may change.\XXX{do we need a figure here?}
%
In the cloud block storage~\cite{}, a \textit{Scan} pattern becomes a \textit{Churn} after some repeated accesses.
%
In the KV store and CDN workloads~\cite{}, the \textit{One-hit wonder} pattern evolves into a \textit{LRU-friendly} or \textit{LFU-friendly} pattern as popular objects emerge.

\subsection{How Existing Cache Eviction Algorithms Perform}

\subsubsection{Static eviction algorithms.}
%
Static eviction algorithms target for predefined access patterns.
%
2Q~\cite{} has a limited ghost space to record the access history, which prefers data hitted more than once in the ghost space.
%
TinyLFU~\cite{} uses a Count-Bloom filter~\cite{} to record access frequency, which favors frequently accessed data.
%
They usually perform well in specific access patterns but poorly in others.

\subsubsection{Adaptive eviction algorithms.}
%
Adaptive eviction algorithms promise to efficiently handle modern 
workloads by adjusting their behavior based on observed access patterns.
%
However, existing adaptive eviction algorithms fall short of this 
promise, to a degree that they are reported to even underperform their static 
counterparts~\cite{}. 
%
Indeed, as mentioned in prior work~\cite{}, converting a static cache eviction 
into an adaptive one even leads to performance degradation.

Our analysis reveals that existing adaptive cache eviction algorithms are ineffective for the following three reasons. 

\PN{Cannot handle important access patterns.}\XXX{maybe a example here?}
\PN{Limited access patterns coverage.}
%
Prior adaptive algorithms have a limited pattern coverage for their binary classification. 
%
They classify functional parts into recency- and frequency-based categories, along with additional sub-functions. 
%
However, each time they invoke only one functional part, resulting in limited coverage.

\PN{the activating algorithm hurts the management of another algorithm}
\DZ{I know that use multiple algorithms is a problem, but what is the real limitation here?}
%
Cacheus~\cite{} and LeCaR~\cite{} invoke two basic static algorithms with different probabilities.
%
When they activate one algorithm, the other algorithm has to evict data that the active algorithm intends to keep, leading to a conflict between the two algorithms.
%
The activated algorithm does not consider the data priority defined by the other algorithm.

\PN{Feedback regulation lacks theoretical guidance.}
\DZ{I know that adapt queue sizes is a problem, but what is the real limitation here?}
CAR~\cite{} and ARC~\cite{} separate data into recency and frequency parts, and adjust the part sizes based on access in the ghost space.
%
The feedback regulation only considers cache misses in the ghost space not cache hits.
%
The empirical heuristics without theoretical guidance cannot judge the marginal benefit of adjusting part sizes accurately.
%
It has to rely on trial-and-error approaches, which are inefficient and may lead to suboptimal performance.

\subsection{The Remaining Gaps in Adaptive Algorithms}

\DZ{Do not work on this subsection yet.}
\DZ{This is a summary subsection.}
\DZ{Make the case that existing adaptive algorithms fail in the following aspects.}

\PN{Gap \#1: Classifying access patterns.}

\PN{Gap \#2: Adapting to access patterns.}

\PN{Gap \#3: Achieving high throughput and multicore scalability.}



\subsection{Access pattern-based analysis}
\label{ss:access-pattern-based-analysis}
Many work analyzes access streams based on metrics to classify them into specific discrete access patterns~\cite{}. 
%
The locality of accesses is an intrinsic property of workloads, which reveals the potential for caching.
%
The temporal locality focuses on the time interval between two accesses to the same object, which is typically measured by the reuse distance~\cite{}.
%
The spatial locality concentrates on the correlation between accesses to different objects, (\eg, adjacent accesses and adjacent addresses)~\cite{}.
%
A frequency-based analysis checks whether the access frequency distribution follows a specific distribution, (\eg, Zipfian distribution)~\cite{}.
%
On the other hand, some work againsts inference accesses, which deviates from the typical access patterns~\cite{}.
%
To deal with real-world behaviors, some work analyzes the daily or long time periodicity of accesses~\cite{}, but this paper discusses the logical access only.
%
Based on the above metrics, there are four typical primitive access patterns: \textit{LFU-friendly}, \textit{LRU-friendly}, \textit{Churn}, and \textit{Scan}~\cite{}.

\textbf{An LFU-friendly pattern} has a skewed access frequency distribution, where a small portion of objects are accessed frequently, and most objects are accessed infrequently.
%
The \textit{LFU} eviction algorithm is the best choice for this pattern, which keeps the frequently accessed objects in the cache and evicts the infrequently accessed ones.

\textbf{An LRU-friendly pattern} has good temporal locality with a small reuse distance, where the recently accessed objects are likely to be accessed again soon.
%
The \textit{LRU} eviction algorithm is the best choice for this pattern, which keeps the recently accessed objects in the cache and evicts the least recently used ones.

\textbf{A \XXX{Churn} pattern} is a set of repeated accesses, where all objects are accessed with equal probability~\cite{}.

\textbf{A Scan pattern} is a set of accesses where all objects are accessed only once, which means it is an interference with no reuse.

However, prior work cannot separate a workload into the above four primitive access patterns perfectly.
%
Most workloads are a mixture of the above primitive access patterns, and the mixture is complex.
%
Some of them are a combination of two or more primitive access patterns, and some of them are not similar to any primitive access patterns.

\subsection{Non-adaptive and adaptive algorithms}
\label{ss:non-adaptive-and-adaptive-algorithms}
Guided by access patterns, an algorithm either covers them statically or adapts to them. 
%
An adaptive algorithm will adjust the operation or cache size for data in different patterns, whereas a non-adaptive algorithm consistently uses a fixed criterion and workflow. 
%
However, adaptive algorithms are not the best choice for various patterns, and a non-adaptive algorithm, S3FIFO, outperforms them in many workloads.

Non-adaptive algorithms make a predefined assumption about access distribution and mainly filter a major access pattern from interference patterns.
%
Deviated from the LRU algorithm, SLRU~\cite{} changes the insertion point to filter out the \textit{Scan} pattern from the \textit{LRU-friendly} pattern.
%
As an algorithm that focuses more on access frequency, WTinyLFU~\cite{} uses a Count-Min Sketch~\cite{} to record long-term access counts for \textit{LFU-friendly} pattern.
%
2Q~\cite{} separates the first access and subsequent accesses to filter out the \textit{Scan} pattern, and S3FIFO~\cite{} leverage three FIFO queues to quickly demote \textit{Scan} pattern.
%
Hyperbolic~\cite{}, LHD~\cite{}, and GDSF~\cite{} consider both access frequency and recency with a new metric to cover both \textit{LFU-friendly} and \textit{LRU-friendly} patterns.
%
With the fixed criterion metric and workflow, these non-adaptive algorithms are reliable in specific access patterns.

Adaptive algorithms adjust the subpart size for patterns or the criterion metric for spatial or temporal adaptive. 
%
Spatial adaptive algorithms, ARC~\cite{} and CAR~\cite{}, separate data into recency and frequency parts, which means \textit{LRU-friendly} and \textit{LFU-friendly} patterns.
%
Then, they use two ghost caches with only metadata for the marginal hit ratios to guide the adjustment of the two parts.
%
Temporal adaptive algorithms, LeCaR~\cite{} and Cacheus~\cite{}, propose a framework, which leverages two basic policies and invokes them with different probabilities.
%
LeCaR uses LRU and LFU as two basic policies, and Cacheus uses LRU-Scan-Resistant and LFU-Churn-Resistant as two basic policies.
%
However, adaptive algorithms cannot separate primitive access patterns perfectly in either spatial or temporal dimensions, and thus subparts of adaptive algorithms duels with each other, rather than cooperating to improve the hit ratio, which incurs a great overhead in the framework.

\subsection{The metastable phenomenon}
\label{ss:the-metastable-phenomenon}
SOTA algorithms are metastable in many benchmarks, which means that they unreliably perform poorly in some workloads.
%
First, we evaluate algorithms in many workloads with different cache sizes and select the algorithm with the highest hit rate in each configuration as the \textbf{dominant algorithm}.
%
Then, we calculate the relative hit ratio to the dominant algorithm for each algorithm.
%
Finally, we group the results by cache size or workload and form CDFs to show the metastable phenomenon.
%
For a workload, the dominant algorithm changes with the cache size.
%
What is more, there are more than \XXX{10\%} of workloads that lose more than \XXX{20\%} performance with a specific algorithm for a given cache size.

The metastable phenomenon of cache eviction algorithms poses a challenge for cache deployment.
%
As shown in figure~\ref{fig:cloudphysics}, when an administrator deploys a single algorithm, about 10\% of workloads tend to have more than 20\% performance loss than expected dominant algorithm.
%
As the cache size changes, the dominant algorithm gradually shifts.
%
Keeping the same eviction algorithm under such changes prevents full utilization of system performance, while using multiple eviction algorithms simultaneously increases management complexity.
\TODO{details}

\textbf{Non-adaptive algorithms} are limited by their design space. 
%
They makes a predefined assumption about access distribution and work well in specific access patterns.
%
However, the filtering mechanism will make wrong decisions in complex access patterns, failed to cover the full spectrum of access patterns.
%
S3FIFO~\cite{} filters out \textit{Scan} pattern, also one-hit wonders, from other patterns, and outperforms others in a small cache size for KV and CDN benchmarks~\cite{}.
%
While a large cache size and block access benchmarks~\cite{} has less one-hit wonders, S3FIFO evicts \textit{infrequent-ephemeral} data, leading to a significant performance degradation.
%

\textbf{Spatial adaptive algorithms} are influenced by changed access patterns. 
%
ARC~\cite{} and CAR~\cite{} separate data into recency and frequency parts, and pattern transition happens only once from recency to frequency.
%
When the access pattern changes, it takes time to evict old data and adjust the part size.
%
To rebalance the marginal hit ratios, they always make a wrong decision, leading to a low hit ratio even with a large cache size.
%
The one-side transition framework explores only a part of interpolation between \textit{LRU-friendly} and \textit{LFU-friendly} patterns.

\textbf{Temporal adaptive algorithms} suffer from a conflict of sub-policies. 
%
CACHEUS~\cite{} and LeCaR~\cite{} invoke two basic policies with different probabilities to cover the design scopes of each base policy.
%
However, in practice, probabilistic invocation can only account for one policy's design scope at a time, leading to a sub-optimal result. 
%
Moreover, under such a framework, policy A may evict the data that policy B focuses on, and the confliction breaks the originally intended interpolated space.