\section{Cache Eviction Algorithms}
\label{s:background}

Software caches are widely deployed in modern systems software to improve performance. 
%
\DZ{Find 8-9 citations for each example below.}
For example, data centers often leverage key-value stores~(\eg, Memcached~\cite{}, Redis~\cite{}) as in-memory caches~\cite{}. 
%
% Ask Zonghao for the citations here.
Almost all modern operating systems use page caches to speed up file 
system operations~\cite{}.
%
Content delivery networks (CDNs)~(\eg, Akamai~\cite{}) cache data on edge servers that are close to end users, thereby minimizing access latency~\cite{}. 

The efficiency of any cache system hinges on its eviction algorithm, since it decides which objects\footnote{We use the term ``object'' to collectively refer to various types of data stored in a cache.} stay in the scarce cache space. 
%
This section provides background on cache eviction algorithms by discussing their key performance metrics~(\S\ref{}) and surveying the state of the art~(\S\ref{}).
%


\subsection{Desired Properties of Cache Eviction Algorithms}
%

\PN{High hit rate.} 
%
Hit rate is arguably the most important metric for an eviction algorithm.  
%
This is because backend storage is often orders of magnitude slower than the cache (consider, \eg, DRAM: access latency 100s of ns vs. SSD: access latency 10s-100s of $\mu$s).
%
Therefore, even a small improvement in hit rate leads to significant end-to-end performance gains.


\PN{Low latency and high throughput.}
%
A high hit rate does not necessarily imply low latency nor high throughput, since an eviction algorithm may incur high operation overhead per access~(\eg, lookup and metadata maintenance). 
%
Thus, an eviction algorithm should minimize such operation overhead.  


\PN{Multicore Scalability.}
%
\DZ{I guess cite some Juncheng Yang's work below and perhaps some other works}
Multicore scalability is increasingly important for modern cache systems, 
which exploit multiple cores to handle large volumes of requests~\cite{}.  
%
With today's servers often equipped with hundreds of CPU cores, an eviction algorithm must avoid scalability bottlenecks to benefit from such parallelism.

\subsection{Evolution of Cache Eviction Algorithms}

\subsubsection{Static Eviction Algorithms}
%
A static algorithm employs a fixed set of rules to perform eviction at all times.
%
Dating back to \XXX{}, early static algorithms, \eg, \lfu~\cite{}, \fifo~\cite{}, and \lru~\cite{}, are based on simple heuristics that work well for specific access patterns.
%
For example, \lru favors an access pattern with high recency, but causes thrashing in scan patterns~(consider, \eg, sequentially accessing a large file).
%

Follow-up work aims to make static algorithms more robust across diverse access patterns.   
%
One thrust of the work, such as \lirs~\cite{} and \lhdc~\cite{}, uses better metrics to rank objects for eviction (rather than, \eg, ranking them by their most recent access, as in \lru).
%
Another thrust of the work, such as \sthreefifo~\cite{} and \twoqueue~\cite{}, leverages multiple components to improve performance.  
%
For example, \sthreefifo uses three FIFO queues, where one short queue quickly demotes objects accessed only once, thereby effectively handling patterns such as scan. 
%
Algorithms, such as \wtinylfu~\cite{}, combine the above two thrusts. 
%
Finally, recent developments in machine learning have led to algorithms that leverage it to predict objects for eviction~\cite{}. 

However, despite their elegant designs, existing static algorithms still struggle to handle the diverse access patterns of modern workloads~(\S\ref{}). 

\XXX{Need to include the description of \lirs here.}
%
\XXX{Need to ensure that the connect of \sthreefifo with the access patterns is clear here.}

\XXX{Perhaps uses PN for \lirs and \sthreefifo?}

% \textbf{An LFU-friendly pattern} has a skewed access frequency distribution, where a small portion of objects are accessed frequently, and most objects are accessed infrequently.
% %
% The \textit{LFU} eviction algorithm is the best choice for this pattern, which keeps the frequently accessed objects in the cache and evicts the infrequently accessed ones.

% \textbf{An LRU-friendly pattern} has good temporal locality with a small reuse distance, where the recently accessed objects are likely to be accessed again soon.
% %
% The \textit{LRU} eviction algorithm is the best choice for this pattern, which keeps the recently accessed objects in the cache and evicts the least recently used ones.

% \textbf{A \XXX{Churn} pattern} is a set of repeated accesses, where all objects are accessed with equal probability~\cite{}.

% \textbf{A Scan pattern} is a set of accesses where all objects are accessed only once, which means it is an interference with no reuse.


\subsubsection{Adaptive Eviction Algorithms}

An adaptive eviction algorithm involves 1) observing and characterizing workload access patterns and 2) adjusting its behavior accordingly~(by, \eg, automatically tuning internal parameters) to maximize performance. 
%
Such adaptiveness promises to make adaptive algorithms \XXX{}.  


Adaptive algorithms fall into two categories: 1) size-adaptive ones and 2) policy-adaptive ones.
%

\PN{A size-adaptive algorithm} partitions the cache into multiple parts and adapts by adjusting each part's size based on access patterns.
%
Representative examples include \arc~\cite{} and \car~\cite{}, both of which follow the principle of dynamically balancing recency and frequency.
%
\arc divides the cache into two LRU lists: a recency list~(that tracks recently accessed objects) and a frequency list~(that tracks frequently accessed objects).
%
A newly accessed object is first placed in the recency list and enters the frequency list upon a second access.
%
Upon a cache hit, \arc increases the size of the corresponding list~(and decreases the size of the other list), thereby favoring recency or frequency based on the current access pattern.
%
\car follows a similar design but replaces the LRU lists with FIFO queues. 

\PN{A policy-adaptive algorithm} adapts by switching between multiple base eviction algorithms according to their effectiveness under observed access patterns.
%
\XXX{Add access pattern classification.}
\XXX{Access pattern: widely defined and used}
\XXX{Access pattern --> base algorithms}

\cacheus~\cite{} and \lecar~\cite{} are the state of the art. 
%
Both works use two base eviction algorithms and maintain a weight for each. 
%
Upon a cache miss, they select one base algorithm to perform the eviction with probabilities proportional to the weights.
%
Next, they check whether a wrongful eviction has occurred by determining whether the requested object appears in the eviction history of either base algorithm.
%
If so, they penalize the corresponding algorithm by decreasing its weight. 
%
Finally, both \cacheus and \lecar use machine learning to control the rate at which weights change.
%





\section{How Modern Algorithms Perform}
\label{s:motivation}

This section analyzes the characteristics of modern cache workloads~(\S\ref{}), evaluates how existing cache eviction algorithms perform on modern workloads~(\S\ref{}), and identifies the remaining gaps in modern algorithms~(\S\ref{}).

\subsection{Characteristics of Modern Cache Workloads}
%
It is well known that modern cache workloads 1) exhibit diverse access patterns and 2) and furthermore, these access patterns evolve over time~\cite{}
%
We confirm this conclusion by analyzing \XXX{} real-world datasets with a total of \XXX{} traces~(\autoref{tbl:traces}). 
%
To our knowledge, this is the largest scale of such analysis to date, where prior work~\cite{} only analyzes \XXX{} workloads with \XXX{} traces.

Figure~\ref{} summarizes our analysis. 
%
As we do not find a prior metric to quantify the diversity and evolution of access patterns, we propose a \XXX{proxy} metric
%
\XXX{}. 

Figure~\ref{} shows 3 examples of evolving and diverse access 
patterns.
%with \XXX{} figures~\footnote{To our knowledge, \XXX{} first proposes this kind of figures without naming them. We name them \textit{} as they \XXX{}}. 
%
In terms of diversity, following the classification in \cacheus~(\S\ref{}), all four patterns appears in these three traces.
%
In terms of evolution, in all three traces, a major access pattern shifts no later than every 10,000 accesses.

\begin{figure}
  \includegraphics[width=\linewidth]{evalresult/relrank_one.png}
  \caption{The average \hitrate improvement over LRU for 9 representative eviction algorithms on 8 real-world workloads. 
  %
  The cache size is set to 3\% of the working set size.
  %
  The larger the value, the better the performance.
  %
  \sys achieves the highest \hitrate in 5 workloads with close to the best performance in 3 workloads.
  }  
  \label{fig:perf}
\end{figure}

\subsection{Performance of Existing Algorithms}
%
\DZ{Everywhere hit/miss ratio --> hit/miss rate. Perhap just replace "ratio" with "rate"}
%
We evaluate the hit rate of \XXX{16} state-of-the-art cache eviction algorithms 
on the real-world workloads discussed in \S\ref{}, and 
%
\autoref{} shows a subset of the results~(See \autoref{} for full results).
%
The subset includes the best-performing algorithms in both the static and adaptive categories~(\S\ref{}).
%

We draw two conclusions from the results. 
%
First, in terms of static algorithms, there is no ``silver bullet'' one that consistently outperforms  others across all workloads.
%
\sthreefifo achieves the highest hit rate in 5 datasets~(excluding \sys), in some cases by a significant margin over the runner-up.
%
In the remaining 3 datasets, \lirs performs the best.
%
As detailed in \S\ref{}, such limitation stems from the inherent nature of static algorithms; 
%
a fixed set of rules seems to be a poor match for the diverse and evolving access patterns.

Second, adaptive algorithms consistently underperform the static 
ones. 
%
None of the adaptive algorithms 1) achieves the highest hit rate in any workload; nor 2) matches the performance of the best static algorithms~(\ie, \sthreefifo) and arguably the second-best one~(\ie, \lirs) across all workloads.
%

This result is surprising, as adaptiveness in cache algorithms is expected to match the diverse and evolving access patterns~(\S\ref{}).
%
Indeed, we view this as an \XXX{outlier} in systems research, as adaptiveness enjoys widespread success in other domains~(\eg, scheduling~\cite{}, \DZ{@Liujia, find more fields, this is an important argument}), 
often resulting in significant performance gains over static approaches.
%
This forms a strong motivation for \sys, that advanced adaptiveness in eviction algorithms to close this gap. 

We next details the performance gaps in existing static~(\S\ref{}) and adaptive algorithms~(\S\ref{}), which serves to explain the two conclusions above. 


\subsection{No ``One-Size-Fits-All'' Static Rules}

\DZ{Waiting for the updates on the \sthreefifo pattern.}


Figure~\ref{fig:patterns}~(c) exhibits a mixed pattern of LRU-friendly and Churn (large reuse distance), where \sys outperforms \lirs significantly.
%
\lirs has a large fixed lru-list to hold objects accessed more than once, a small lru-list for others, and a ghost list to track evicted objects.
%
Each object in \lirs has a timestamp of the last access, 0 for newly added objects, which is updated on each hit.
%
\lirs will compare the timestamp of the accessed object with the minimum timestamp in the large lru-list (tail of the large lru-list).
%
If the accessed timestamp is larger, the object is promoted to the large lru-list; otherwise, it is added to the small lru-list.
%
This helps \lirs filters churn objects effectively when the churn size is large.
%
However, when LRU-friendly objects appear with churn or repeated objects with different reuse distances, \lirs holds repeated objects in the small lru-list in a reservation manner.
%
\sys will not be affected by this situation, as it identifies \popular objects and holds them.

Figure~\ref{fig:patterns}~(d)
%
S3-FIFO has a strict threshold to filter one-hit wonder (Scan) in the small cache, which prefers burst data accessed in a short period. 
%
When churn appears with LRU-friendly data, S3-FIFO evicts churn and other infrequently accessed data in the ghost cache for observation. 
%
If the amount of data exceeds the ghost size, S3-FIFO cannot capture any of it. 
%
In contrast, \sys has a dynamic threshold, which avoids threshing the ghost. In another case, if the churn size is larger than the cache size, \sys will hold part of them as \cold \popular data.

\subsection{The Remaining Gaps in Adaptive Algorithms}

Our analysis reveals two three limitations in existing adaptive algorithms that lead to their poor performance.

\XXX{Consider a table to make the argument.}
\PN{Limitation \#1: Corase-grained characterization approach.}
%
An inherent limitation of prior adaptive algorithms is that they can adapt to 
only a narrow set of access patterns.
%
\autoref{} summarizes the access patterns that existing adaptive algorithms can handle.
%
As we elaborate next, the root cause lies in their approaches to characterize workload access patterns. 

The design of \arc and \car considers only three primitive 
access patterns~(\S\ref{}): \textit{LRU-friendly}, \textit{LFU-friendly}, and \textit{Scan}, while ignoring the \textit{Churn} pattern. 
%
Specifically, \DZ{@Liujia, explain how does \arc and \car adapt to these three patterns, and why it fails on the churn pattern.}
%

\autoref{} shows an representative trace that \car performs poorly.
%
In this case, \car fails to cache those frequently accessed 
objects in the churn pattern, but rather wastes cache space on \XXX{}, leading 
to a low hit rate. 
%

While \cacheus improves upon \arc and \car by considering the \textit{Churn} pattern~(\S\ref{}), it still fails to adapt to many real-world access patterns.
%
The issue lies in the granularity of its access pattern characterization approach. 
%
\cacheuss characterization, while complete, is too corase-grained. 
%
The four primitive access patterns characterize workload behavior at the \XXX{subtrace} level, that is, the access patterns of a group of objects over a 
period of time. 
%

However, as shown in \autoref{}, multiple primitive patterns~(in this case, all four of them) may coexist.  
%
Therefore, in most of the time, the access pattern do not fall into any one of the four primitive patterns.
%
\XXX{Hint in the background that they are designed for primitive patterns only.}
This renders both base algorithms in \cacheus ineffective, as the base algorithms are designed to handle these primitive patterns~(\S\ref{}). 
%
In this case, SR-LRU evicts the \XXX{}, while CR-LFU evicts \XXX{}. 
%
The poor performance of both base algorithms leads to the poor performance of \cacheus.


% Adapting to access patterns 
\PN{Limitation \#2: Ineffective \XXX{to adapt}}
%
There are multiple sub-optimal points for parameters (non-convex) in \cacheus, making it hard to find the best one.
%
\arc adjusts the cache size for recency and frequency adaptively.
%


\PN{Limitation \#3: Poor multicore performanace.}
%
The first two limitations concern hit rate, but even with high hit rates, existing adaptive algorithms still suffer from poor multicore scalability, an increasingly important criterion for eviction algorithms~(\S\ref{}).
%

\autoref{} shows the multicore scalability of \arc and \cacheus, where 
the throughput of both algorithms stop increasing after \XXX{} threads with a significant gap to state-of-the-art static algorithms. 
%
This is because both algorithms use LRU, which requires locking the whole list to move an object to the head upon each access.


\begin{figure*}
    \centering

    \begin{minipage}{0.24\textwidth}
        \centering
        \includegraphics[width=\linewidth]{fig/io_traces.ns269.oracleGeneral.zstcompare.jpg}
    \end{minipage}
    \hfill
    \begin{minipage}{0.24\textwidth}
        \centering
        \includegraphics[width=\linewidth]{fig/io_traces.ns269.oracleGeneral.zstcomparearc.jpg}
        \caption{arc}
    \end{minipage}
    \hfill
    \begin{minipage}{0.24\textwidth}
        \centering
        \includegraphics[width=\linewidth]{fig/tencentBlock.ns10011.oracleGeneral.zstcompare.jpg}
    \end{minipage}
    \hfill
    \begin{minipage}{0.24\textwidth}
        \centering
        \includegraphics[width=\linewidth]{fig/tencentBlock.ns16470.oracleGeneral.zstcompare.jpg}
    \end{minipage}
    
  \caption{The accessed object over time of three traces~(\XXX{}) from production datasets. 
  %
  The $x$-axis is the access sequence number, and the $y$-axis is the object ID sorted by the first access time.
  %
  A point means that the object is accessed at that time.
  %
  We do not show the full traces for clarity. 
  }
  \label{fig:cac}
\end{figure*}

\XXX{Conflict}
\XXX{binary classification}
\XXX{It has to rely on trial-and-error approaches,}
\XXX{Robust across cache sizes}


