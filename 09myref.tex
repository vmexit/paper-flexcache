\section{myref}
replacement policy:
Ditto~\cite{shen2023ditto}, S3FIFO~\cite{yang2023fifo}, LHD~\cite{beckmann2018lhd}, TinyLFU~\cite{einziger2017tinylfu},CACHEUS~\cite{rodriguez2021learning}
HALP~\cite{song2023halp},GL-Cache~\cite{yang2023gl},LRB~\cite{yang2023gl},Hyperbolic~\cite{blankstein2017hyperbolic},TwoQ~\cite{johnson19942q}
MQ~\cite{zhou2001multi},ARC~\cite{megiddo2003arc},CAR~\cite{bansal2004car},LIRS~\cite{jiang2002lirs},Belady~\cite{belady1966study}

Hot Object Cache (HOC) maximize the object hit ratio (OHR) AdaptSize~\cite{berger2017adaptsize} is a novel Markov cache model 

prefetch:
Baleen~\cite{wong2024baleen}(CXL prefetch)
MITHRIL~\cite{yang2017mithril}
ASP~\cite{baek2008prefetching}
kernel prefetch disk~\cite{butt2005performance}

cliff removing Talus~\cite{beckmann2015talus},Cliffhanger~\cite{cidon2016cliffhanger},

sampling
SHARDS~\cite{waldspurger2015efficient},Miniature~\cite{waldspurger2017cache},Kosmo~\cite{shakiba2024kosmo}
stack distance~\cite{suh2002new,kim1991implementing,mattson1970evaluation}
footprint sampling for lru~\cite{xiang2011linear,xiang2011all}
counter stack~\cite{wires2014characterizing}
aet~\cite{hu2018fast,hu2016kinetic}
HOTL~\cite{xiang2013hotl}
size aware:FLOWS~\cite{guo2024flows},EAET~\cite{pan2019lightweight,pan2021penalty}

optimize
latency aware: pRedis~\cite{pan2021penalty,pan2019predis} Delayed hits~\cite{atre2020caching}
TTL-based CDN~\cite{basu2018adaptive}
SSD write efficient WEC~\cite{chai2015wec}
profiling applications and dynamically tailoring memory resources and eviction policies Dynacache~\cite{cidon2015dynacache}


studied offline, optimal policies for integrated caching and prefetching~\cite{cao1995study}
work adaptively balancing cache amongst three partitions: LRU cache, hinted cache, and prefetch cache~\cite{patterson1995informed}.
SARC 
separates access and prefetch data into two partitions, and adaptively adjusts the cache size of each partition based on margin function.
We shall develop an adaptive, self-tuning, low overhead algorithm that dynamically partitions the amount
of cache space amongst sequential and random data so as to minimize the overall miss rate.~\cite{gill2005sarc}

prior work propose a global clean page first replacement (GCPF) to reduce the write operations to NVM with an index-aware multistream prefetcher (IAMSP) that considers the indexes of prefetch candidates individually so as to prefetch pages from NVM more accurately~\cite{lin2019global}(seems like two functional parts)

MISC
libcachesim~\cite{libcachesim}
MSR~\cite{storage2010msr,narayanan2008write}
FIU~\cite{koller2010deduplication}
Cloudphysics~\cite{waldspurger2015efficient}
Tencent Photo~\cite{zhou2016tencent,zhou2018demystifying}
WikiMedia CDN~\cite{wikimedia}
Systor~\cite{lee2016systor,lee2017understanding}
Tencent CBS~\cite{zhang2018tencent,zhang2020osca}
Alibaba~\cite{Alibaba,li2020depth,wang2022separating}
Twitter~\cite{yang2021large}
Meta KV~\cite{meta}
Meta CDN~\cite{meta}
CacheLib~\cite{berg2020cachelib}
Zipfan's law~\cite{breslau1999web,breslau1998implications}
twolevel hierarchical caching system(Zipf distribution)~\cite{che2001analysis}
propose a offline policy keeps the hit ratio as MIN and reduces flash erasures~\cite{cheng2016erasing} 